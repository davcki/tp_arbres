{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Travail Pratique 2 - ARBRES\n",
        "author: David Czarnecki\n",
        "format: html\n",
        "toc: true\n",
        "number-sections: true\n",
        "---"
      ],
      "id": "268dccb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: true\n",
        "#| echo: false\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rc\n",
        "\n",
        "from sklearn import tree, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tp_arbres_source import (rand_gauss, rand_bi_gauss, rand_tri_gauss,\n",
        "                              rand_checkers, rand_clown,\n",
        "                              plot_2d, frontiere)\n",
        "\n",
        "\n",
        "rc('font', **{'family': 'sans-serif', 'sans-serif': ['Computer Modern Roman']})\n",
        "params = {'axes.labelsize': 6,\n",
        "          'font.size': 12,\n",
        "          'legend.fontsize': 12,\n",
        "          'text.usetex': False,\n",
        "          'figure.figsize': (10, 12)}\n",
        "plt.rcParams.update(params)\n",
        "\n",
        "sns.set_context(\"poster\")\n",
        "sns.set_palette(\"colorblind\")\n",
        "sns.set_style(\"white\")\n",
        "_ = sns.axes_style()"
      ],
      "id": "4a71d385",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On simule une réalisation d'un échantillon de taille 456 avec la fonction rand_checkers définie dans **tp_arbres_source.py**.\n"
      ],
      "id": "65ba366b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: true\n",
        "\n",
        "n1 = 118\n",
        "n2 = 118\n",
        "n3 = 118\n",
        "n4 = 120\n",
        "sigma = 0.1\n",
        "data4 = rand_checkers(n1, n2, n3, n4, sigma)"
      ],
      "id": "a211bdc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On crée deux objets : *dt_entropy* et *dt_gini* à partir de la fonction *DecisionTreeClassifier* du module **tree** qui nous servent à créer deux arbres de décision (selon le critère de l'entropie et selon le critère de gini pour le deuxième) à partir de nos observations *data4*.\n"
      ],
      "id": "35b5bc46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: true\n",
        "\n",
        "dt_entropy = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "dt_gini    = tree.DecisionTreeClassifier(criterion=\"gini\")"
      ],
      "id": "c0ff4485",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A partir de l'ensembe d'apprentissage *data4*, on nomme *X_train* les observation (qui sont des couples) et *y_train* leurs étiquettes.\n"
      ],
      "id": "717f93d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: true\n",
        "\n",
        "data = data4\n",
        "\n",
        "n_samples = len(data)\n",
        "\n",
        "X_train   = data4[:,0:2]\n",
        "y_train   = data4[:,2].astype(int)"
      ],
      "id": "edaba647",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour i allant de 1 à 12, on calcule le pourcentage d'erreurs commises par les deux arbres dont la profondeur est fixée à i (le pourcentage d'erreurs est donné par le module **score** de la fonction **DecisionTreeClassifier**).\n",
        "On obtient ainsi le pourcentage d'erreur de chaque arbre en fonction de leur profondeur, on trace leurs courbes.\n"
      ],
      "id": "1c9f307d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dmax = 12\n",
        "scores_entropy = np.zeros(dmax)  #vecteur qui contiendra les score des arbres entropy\n",
        "scores_gini = np.zeros(dmax)     #vecteur qui contiendra les score des arbres gini\n",
        "\n",
        "plt.figure(figsize=(15, 10))     #formalité graphique\n",
        "\n",
        "for i in range(dmax):\n",
        "    dt_entropy = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=i+1)\n",
        "    dt_entropy.fit(X_train, y_train)\n",
        "    scores_entropy[i] = dt_entropy.score(X_train, y_train)\n",
        "\n",
        "    dt_gini = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=i+1)\n",
        "    dt_gini.fit(X_train, y_train)\n",
        "    scores_gini[i] = dt_gini.score(X_train, y_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(dmax), scores_entropy, label=\"entropy\")\n",
        "plt.plot(np.arange(dmax), scores_gini, label=\"gini\")\n",
        "plt.xlabel('Max depth')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.legend()\n",
        "plt.draw()\n",
        "print(\"Scores with entropy criterion: \", scores_entropy)\n",
        "print(\"Scores with Gini criterion: \", scores_gini)"
      ],
      "id": "06e49488",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}